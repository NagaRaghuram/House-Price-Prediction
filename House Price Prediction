                                                                                         House Price Prediction



Introduction:
         House Price Prediction is a machine learning project designed to predict house prices based on various features such as square footage, the number of bedrooms, location,and 
more.The project aims to provide accurate price estimates using data-driven models, which can be beneficial for real estate agents, buyers, and sellers.

Features:
>>Data Preprocessing: Handling missing values, encoding categorical variables, and feature scaling.
>>Model Training: Implementation of multiple regression models.
>>Evaluation: Performance metrics such as RMSE, MAE, and R^2 Score.
>>Data Visualization: Graphical representations of data and model performance.
>>Prediction Interface: Simple interface to input house features and get a price prediction.

Data:
https://www.kaggle.com/datasets/prevek18/ames-housing-dataset

Modeling Approach:
The project employs various machine learning models to predict house prices, including:
>>Linear Regression: A baseline model that assumes a linear relationship between features and the target.
>>Random Forest: An ensemble model that uses multiple decision trees to improve prediction accuracy.
>>Gradient Boosting: A powerful model that builds trees sequentially, focusing on correcting the errors of previous models.

Evaluation:
The performance of the models is evaluated using the following metrics:
>>Root Mean Squared Error (RMSE): Measures the average magnitude of the error.
>>Mean Absolute Error (MAE): Measures the average absolute error.
>>R^2 Score: Indicates how well the model explains the variance in the target variable.

Configuration:
The project can be customized using configuration files or command-line arguments. Key configurable parameters include:
>>Training/Testing Split: Adjust the ratio of training to testing data.
>>Model Hyperparameters: Customize hyperparameters for each model (e.g., number of trees in Random Forest).
>>Feature Selection: Enable or disable certain features used in model training.

Source Code:
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
import matplotlib.pyplot as plt
# Load the dataset
df = pd.read_csv('C:/Users/likes/Downloads/House Price Predictions.zip')


# Display basic information
print(df.info())

# Display first few rows of the dataset
print(df.head())
# Separate features and target variable
X = df.drop('SalePrice', axis=1)
y = df['SalePrice']

# Select numerical and categorical columns
num_features = X.select_dtypes(include=['int64', 'float64']).columns
cat_features = X.select_dtypes(include=['object']).columns

# Preprocessing for numerical data
num_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

# Preprocessing for categorical data
cat_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

# Combine preprocessing steps
preprocessor = ColumnTransformer(
    transformers=[
        ('num', num_transformer, num_features),
        ('cat', cat_transformer, cat_features)
    ])

# Preprocessing and model pipeline
model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('model', LinearRegression())
])
# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the model
model.fit(X_train, y_train)
# Predict the prices of the test set
y_pred = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")

# Compare actual vs predicted prices
comparison = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})
print(comparison.head())

# Plot actual vs predicted prices
plt.scatter(y_test, y_pred)
plt.xlabel("Actual Prices")
plt.ylabel("Predicted Prices")
plt.title("Actual vs Predicted Prices")
plt.show()

Contact details:
For any questions or suggestions, feel free to reach out:
Email:nagaraghuram40@gmail.com


